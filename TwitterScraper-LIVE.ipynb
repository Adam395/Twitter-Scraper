{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requisite modules\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os #Library module for .csv file check\n",
    "from twitterscraper import query_tweets #if you haven't installed this module, run 'pip install twitterscraper' in your notebook\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "query_list = [ #This is our sample list, add or subtract as you see fit!\n",
    "    'COVID',\n",
    "    'COVID-19',\n",
    "    'Corona',\n",
    "    'Coronavirus',\n",
    "    'Rona',\n",
    "    'Quarantine',\n",
    "    '#COVID',\n",
    "    '#COVID-19',\n",
    "    '#quarantine',\n",
    "    '#Quarantine',\n",
    "    '#covid19'\n",
    "]\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#Credit to Danielle Medellin, DSI11-NYC for the below implementation of custom parameter dictionary support\n",
    "custom_params = {'Houston':{'lat'  : 29.760427,\n",
    "                         'long' : -95.369804,\n",
    "                         'radius': '15mi',\n",
    "                         'queries' : ['rona','corona','covid']},\n",
    "              'Detroit': {'city' : 'Detroit',\n",
    "                          'lat'  : 42.331429,\n",
    "                          'long' : -83.045753,\n",
    "                          'radius' : '10mi',\n",
    "                         'queries': ['stonks','tom nook','animal crossing']}\n",
    "             }\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#Get tweets without geolocation\n",
    "def get_tweets(query): \n",
    "    tweets = {} #Instantiates a new empty dictionary\n",
    "    count = 0 #Instantiates an index generator\n",
    "    for tweet in query_tweets(query,begindate=datetime.date(2019,12,1)):\n",
    "        chirp = {} #Instantiates a new empty dictionary for each pulled tweet\n",
    "        chirp['tweet_id'] = tweet.tweet_id\n",
    "        chirp['username'] = tweet.username\n",
    "        chirp['text'] = tweet.text\n",
    "        chirp['tweet_date'] = tweet.timestamp\n",
    "        chirp['search_term'] = query\n",
    "        chirp['city'] = np.NaN #Fills columns with NaNs for data cleaning at a later point. These items are NaNs so that\n",
    "        chirp['lat'] = np.NaN #They will be flagged in an EDA search for missing values, instead of being strings with no information\n",
    "        chirp['long'] = np.NaN\n",
    "        chirp['radius'] = np.NaN\n",
    "        tweets.update({count : chirp}) #Sets count value to tweets keys, so that index is automatically generated \n",
    "        count += 1 #increments index up by 1\n",
    "    return tweets\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#Get tweets with geolocation\n",
    "def get_tweets_geoloc(query, city, lat, long, radius): #Geolocation parameters defined by user in master function or dictionary\n",
    "    tweets = {}\n",
    "    count = 0\n",
    "    for tweet in query_tweets(f\"{query}, geocode:{lat},{long},{radius}\",begindate=datetime.date(2019,12,1)):\n",
    "        chirp = {} #Generates tweet dictionary by calling on generated 'tweet' object attributes\n",
    "        chirp['tweet_id'] = tweet.tweet_id\n",
    "        chirp['username'] = tweet.username\n",
    "        chirp['text'] = tweet.text\n",
    "        chirp['tweet_date'] = tweet.timestamp\n",
    "        chirp['search_term'] = query\n",
    "        chirp['city'] = city\n",
    "        chirp['lat'] = lat\n",
    "        chirp['long'] = long\n",
    "        chirp['radius'] = radius\n",
    "        tweets.update({count : chirp}) #Sets count value to tweets keys, so that index is automatically generated \n",
    "        count += 1 #increments index up by 1\n",
    "    return tweets\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#Generate dataframe from \"tweets\" dictionary generated after each query\n",
    "def make_dataframe(dictionary):\n",
    "    df = pd.DataFrame.from_dict(dictionary, orient='index') #Creates a dataframe from the input dictionary 'tweets' later in function\n",
    "    return df #creates a temporary dataframe for concatenation later\n",
    "#--------------------------------------------------------------------\n",
    "\n",
    "#Query function using custom parameters\n",
    "#Credit Danielle Medellin for this code block section\n",
    "def get_query_dataframe_cp(custom_params):\n",
    "    query_df = pd.DataFrame() #instantiate an empty dataframe\n",
    "    for key in custom_params.keys(): #Generates a new query dataframe for each city used in the parameter dictionary\n",
    "        for query in custom_params[key]['queries']: #Runs a unique query for each unique term in the query key\n",
    "            tweets = get_tweets_geoloc(query,custom_params[key],custom_params[key]['lat'],custom_params[key]['long'],custom_params[key]['radius'])\n",
    "            df = make_dataframe(tweets) #creates temporary dataframe from independent query\n",
    "            query_df = pd.concat([query_df,df],ignore_index = True) #concatenates temporary dataframe 'df' to master query dataframe \n",
    "    return query_df\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "#Query function with geolocation but no custom parameters\n",
    "def get_query_dataframe_geo(list_of_queries,city,lat,long,radius):\n",
    "    query_df = pd.DataFrame()\n",
    "    for query in list_of_queries: #Runs the same functions as custom parameters code\n",
    "            tweets = get_tweets_geoloc(query,city,lat,long,radius)\n",
    "            df = make_dataframe(tweets)\n",
    "            query_df = pd.concat([query_df,df],ignore_index = True)\n",
    "    return query_df\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "#Query function with no custom anything\n",
    "def get_query_dataframe(list_of_queries):\n",
    "    query_df = pd.DataFrame()\n",
    "    for query in list_of_queries:\n",
    "            tweets = get_tweets(query)\n",
    "            df = make_dataframe(tweets)\n",
    "            query_df = pd.concat([query_df,df],ignore_index = True)\n",
    "    return query_df\n",
    "#------------------------------------------------------------------\n",
    "\n",
    "#Master function\n",
    "def get_dataset():\n",
    "    \n",
    "    #Main function switches\n",
    "    custom_params_switch = input(\"Are you using a custom parameter dictionary?\")\n",
    "    if str.lower(custom_params_switch) == 'yes':\n",
    "        pass #Proceeds to CSV switches if user is using custom parameter dictionary\n",
    "    else:\n",
    "        geo_switch = input(\"Are you using geolocation?\") #Checks if user wants to use geolocation if only using a query list\n",
    "    \n",
    "    #CSV parameter switches\n",
    "    export_csv_switch = input(\"Do you want to export the final dataframe to csv?\")\n",
    "    if str.lower(export_csv_switch) == 'yes': #Enables CSV switch block later if yes as well\n",
    "        custom_csv_name = input(\"Input CSV export file name:\") #Prompts user for file name\n",
    "        if os.path.exists(f'datasets/{custom_csv_name}.csv') == True: #Check if file has already been created. If yes, prompt user to overwrite or make new file.\n",
    "            overwrite_check = input (\"File already exists--do you want to overwrite?\")\n",
    "            if str.lower(overwrite_check) == 'yes':\n",
    "                pass #skips through checks and overwrites file name\n",
    "            else:\n",
    "                new_csv_name = custom_csv_name #creates new_csv_name variable = to old name\n",
    "                while new_csv_name == custom_csv_name: #continues to reject file name until a unique name is created\n",
    "                    new_csv_name = input(\"Input new output file name:\")\n",
    "                custom_csv_name = new_csv_name #Sets the file name to the new user input\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #Query parameter switch block\n",
    "    if str.lower(custom_params_switch) == 'yes':\n",
    "        dataset = get_query_dataframe_cp(custom_params)\n",
    "    else:\n",
    "        if str.lower(geo_switch) == 'yes':\n",
    "            lat = float(input(\"Input Latitude:\")) #Converts string input latitude to float value\n",
    "            long = float(input(\"Input Longitude:\"))\n",
    "            city = input(\"Input city or neighborhood corresponding to coordinates:\") #Allows filling of city values\n",
    "            radius = input(\"Input radius and unit:\")\n",
    "            dataset = get_query_dataframe_geo(query_list, city, lat, long, radius)\n",
    "        else:\n",
    "            dataset = get_query_dataframe(query_list)\n",
    "    \n",
    "    #CSV export block\n",
    "    if str.lower(export_csv_switch) == 'yes':\n",
    "        if os.path.exists('datasets') == True:\n",
    "            pass\n",
    "        else:\n",
    "            os.mkdir('datasets')\n",
    "        dataset.to_csv(f\"./datasets/{custom_csv_name}.csv\", index = False) #write csv to datasets folder\n",
    "        print(f\"Export complete, scraped {len(dataset.index)} tweets\") #Prints completion statement including total tweets scraped\n",
    "        \n",
    "    else:\n",
    "        return dataset        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
